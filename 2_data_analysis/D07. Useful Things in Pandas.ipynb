{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D07: Useful things in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Binning & Categorical Ordering\n",
    "* Duplicates\n",
    "* Pivot\n",
    "* Datetime format\n",
    "* String Slicing\n",
    "* Stack / Unstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String slicing in pandas is just as easy as in regular Python using the .str method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'uid': [1000,1001,1001,1002,1002,1003,1004,1005],\n",
    "                    'data1':['Aaaaa1','Baaaa2','Baaaa3','Caaaa4','Daaaa5','Eaaaa6','Faaaa7','Gaaaa8']})\n",
    "\n",
    "df['Capital'] = df['data1'].str[0:1]    # First 1\n",
    "df['Trails'] = df['data1'].str[1:]      # Everything from 2nd\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Binning & Categorical Ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href = \"https://en.wikipedia.org/wiki/Data_binning\">Binning</a> is the process of separating numeric continuous data into representative categorical 'bins'. A good example of this is creating categorical decages based upon numeric year data.\n",
    "\n",
    "There is a good example of this <a href = \"http://chrisalbon.com/python/pandas_binning_data.html\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data = {'regiment': ['Nighthawks', 'Nighthawks', 'Nighthawks', 'Nighthawks', 'Dragoons', 'Dragoons', \n",
    "                         'Dragoons', 'Dragoons', 'Scouts', 'Scouts', 'Scouts', 'Scouts'], \n",
    "            'company': ['1st', '1st', '2nd', '2nd', '1st', '1st', '2nd', '2nd','1st', '1st', '2nd', '2nd'], \n",
    "            'name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze', 'Jacon', 'Ryaner', 'Sone', 'Sloan', 'Piger', 'Riani', 'Ali'], \n",
    "            'preTestScore': [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3],\n",
    "            'postTestScore': [25, 94, 57, 62, 70, 25, 94, 57, 62, 70, 62, 70]}\n",
    "df = pd.DataFrame(raw_data, columns = ['regiment', 'company', 'name', 'preTestScore', 'postTestScore'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins = [0, 25, 50, 75, 100]\n",
    "group_names = ['Low', 'Okay', 'Good', 'Great']\n",
    "categories = pd.cut(df['postTestScore'], bins, labels=group_names)\n",
    "df['categories'] = pd.cut(df['postTestScore'], bins, labels=group_names)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with many categorical variables, alphabetical order isn't necessariuly the best order in which to present the data. \n",
    "\n",
    "In such cases you can use the Categorical class to define a custom order as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'station': ['London','York','Newcastle','London','York','Newcastle','London','York','Newcastle','London','York','Newcastle'],\n",
    "                   'value':[45000,18000,20000,36000,23000,22000,93000,45000,42000,96000,88000,54000]})\n",
    "\n",
    "df['station'] = pd.Categorical(df['station'],['London','York','Newcastle'])  # Creating the Categorical Variable\n",
    "gp1 = df.groupby(['station']).sum()                                          # Groupby  \n",
    "gp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate records can cause havoc if not picked up! Pandas has a number of options for dealing with these, both for the overall dataframe and for individual columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'uid': [1000,1001,1001,1002,1002,1003,1004,1005],\n",
    "                  'data1':['A','B','B','C','D','E','F','G']})\n",
    "df1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dup = df1.duplicated()              # Finds duplicates\n",
    "df2 = df1.drop_duplicates()         # Drops duplicates\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless you provide it with an argument, the drop_duplicates() method will look at all the data in the dataframe and only drop records that are have duplicated data in all the columns (1 & 2 but not 3 & 4). The .duplicated() method works in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However when we specify a column, it behaves differently and will drop all duplicates in that column regardless of what the rest of the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4 = df1.drop_duplicates(['uid'])    # Drops duplicates in the specified column - Defaults to keep the first duplicate\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pandas will always default to keeping the first duplicate unless you specify otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df5 = df1.drop_duplicates(['uid'],keep='last')  # Keeping the last record\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivoting allows you to change the shape of your datasets. In the example below we can see that the data is in 'long' form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'time':[1,1,1,2,2,2,3,3,3,4,4,4],\n",
    "                   'category':['A','B','C','A','B','C','A','B','C','A','B','C'],\n",
    "                   'data':np.random.randint(0,1000,12)*100})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the pivot function we can transpose this data to 'wide' form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df.pivot(index='time', columns='category', values='data')\n",
    "df2.index.name = None\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack & Unstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack and unstack are functions that allow you to reshape your dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(8).reshape((2, 4)),\n",
    "                  index=pd.Index(['LA', 'SF'], name='city'),\n",
    "                  columns=pd.Index(['col1', 'col2', 'col3','col4'], name='letter'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.stack()     # Stack 'stacks' the columns into a series\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.unstack() # Stack 'unstacks' the series back into a dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datetime Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has it's own specific <a href = \"https://docs.python.org/3.5/library/datetime.html\">Datetime built-in package</a> for dealing with datetime data. You can find a good overview of this <a href = \"http://effbot.org/librarybook/datetime.htm\">here</a>, however we'll now look at how you can deal with datetime format in pandas.\n",
    "\n",
    "First we'll import some data with some dates in it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'date':['11/05/2016','18/05/2016','01/06/2016','08/06/2016','15/06/2016'],  # Importing some dates as a string\n",
    "                   'data':np.random.randint(0,1000,5)*100})                                    # Some random data\n",
    "df = df.sort_values(by=['date'])                                                               # Sorting the values by date\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, Python doesn't recognise the values as dates. However we can change that by using the to_datetime function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dttm(row):\n",
    "\ttry:\n",
    "\t\treturn pd.to_datetime(row['date'],dayfirst=True, format= \"%d/%m/%Y\") \n",
    "\texcept ValueError:\n",
    "\t\tpass\n",
    "    \n",
    "df['datetime'] = df.apply(dttm,axis=1)\n",
    "df = df.sort_values(by=['datetime'])  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(df['datetime'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format = argument look a little bit daunting at first but the syntax is deceptively simple...\n",
    "\n",
    "Each of the values relates to a specifc format as follows:\n",
    "\n",
    "    %d Day of the month as a zero-padded decimal number (e.g. 30)\n",
    "    %m Month as a zero-padded decimal number. (e.g. 09)\n",
    "    %Y Year with century as a decimal number. (e.g. 2013)\n",
    "    \n",
    "The - in the argument represents the delimiter between the values.\n",
    "\n",
    "Also note that we pass the dayfirst = True argument. This is to prevent the month appearing first as per the US convention for displaying dates!\n",
    "\n",
    "Let's look at a slightly different example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df2 = pd.DataFrame({'date':['11-May-16','18-May-16','01-Jun-16','08-Jun-16','15-Jun-16'], # Importing some dates as a string\n",
    "                   'data':np.random.randint(0,1000,5)*100})                               # Some random data\n",
    "df2 = df2.sort_values(by=['date'])                                                        # Sorting the values by date\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the delimiters and formats are different so we need to pass different tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dttm2(row):\n",
    "\ttry:\n",
    "\t\treturn pd.to_datetime(row['date'], dayfirst=True, format= \"%d-%b-%y\") \n",
    "\texcept ValueError:\n",
    "\t\tpass\n",
    "    \n",
    "df2['datetime'] = df2.apply(dttm2,axis=1)\n",
    "df2 = df2.sort_values(by=['datetime'])  \n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the codes we're using are as follows:\n",
    "\n",
    "    %d Day of the month as a zero-padded decimal number (e.g. 30)\n",
    "    %b Month as localeâ€™s abbreviated name. (e.g. Sep)\n",
    "    %y Year without century as a zero-padded decimal number. (e.g. 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, Pandas handles DateTime values in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'date':['11-May-16 06:01:23','18-May-16 12:22:01','01-Jun-16 18:51:34',\n",
    "                            '08-Jun-16 23:19:16','15-Jun-16 00:01:04'],                      # Importing some datetimes\n",
    "                   'data':np.random.randint(0,1000,5)*100})                                  # Some random data\n",
    "\n",
    "\n",
    "def dttm3(row):\n",
    "\ttry:\n",
    "\t\treturn pd.to_datetime(row['date'],dayfirst=True, format= \"%d-%b-%y %H:%M:%S\") \n",
    "\texcept ValueError:\n",
    "\t\tpass\n",
    "    \n",
    "df3['datetime'] = df3.apply(dttm3,axis=1)\n",
    "df3 = df3.sort_values(by=['datetime'])  \n",
    "df3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find a full reference of the datetime tokens and what they mean <a href = \"http://strftime.org/\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll also notice that I've used try/except blocks instead of if/elif. This is because a lot of real world date data has inconsistencies and issues with it and try/except will allow you to specify an exception handling process to account for it."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
